Metadata-Version: 2.4
Name: askg
Version: 0.1.0
Summary: Agent-Server Knowledge Graph
Author: ASKG Team
Requires-Python: >=3.9
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: pydantic>=2.0.0
Requires-Dist: neo4j>=5.0.0
Requires-Dist: aiohttp>=3.8.0
Requires-Dist: beautifulsoup4>=4.11.0
Requires-Dist: requests>=2.28.0
Requires-Dist: pyyaml>=6.0
Requires-Dist: python-dotenv>=0.19.0
Requires-Dist: asyncio-throttle>=1.0.0
Requires-Dist: langgraph>=0.0.20
Requires-Dist: langchain>=0.1.0
Requires-Dist: langchain-openai>=0.0.5
Requires-Dist: openai>=1.0.0
Provides-Extra: dev
Requires-Dist: pytest>=7.0.0; extra == "dev"
Requires-Dist: pytest-asyncio>=0.21.0; extra == "dev"
Requires-Dist: pytest-cov>=4.0.0; extra == "dev"
Requires-Dist: black>=22.0.0; extra == "dev"
Requires-Dist: ruff>=0.1.0; extra == "dev"
Dynamic: license-file

# askg
## Agent-Server Knowledge Graph

---

## Documentation

All project documentation (except this README) is now located in the `docs/` directory. Key documents include:

- `docs/LANGGRAPH_ORCHESTRATOR.md` — LangGraph Orchestrator documentation
- `docs/NEO4J_INSTANCES.md` — Neo4j instance information
- `docs/ASSESSMENT_SUMMARY.md` — Assessment summary
- `docs/PROGRESS_BARS.md` — Progress bars documentation
- `docs/SCALE_IMPROVEMENT_PLAN.md` — Scale improvement plan
- `docs/SCALE_IMPROVEMENT_RESULTS.md` — Scale improvement results
- `docs/MCPMARKET_INTEGRATION.md` — MCP Market integration
- `docs/Claude.md/Agent-Server Knowledge Graph` — Claude agent-server knowledge graph notes

For additional guides and technical references, see the `docs/` directory and its subfolders.

---

This is the repository for the ASKG, a project of OAKS, the Open-source Agentic AI Knowledge Stack.

OAKS is a collaboratory, comprised of a set of OSS AI partners and their projects that can be integrated with one another, forming a stack for writing AI applications.

OAKS is maintained as a Notion workspace at 

oaks.town

The ASKG project aims to maintain a knowledge graph of MCP servers and A2A agents that could be used both by himans and AI developer tools to write composable workflows.

We aim to automate the ingestion of MCP server definitions and make the knowledge graph publicly available.  Neo4j provides an instance of AuraDB, a cloud Neo4j database, to host, visualize, and analyze the graph.

*askg* comprehensive knowledge graph system for Model Context Protocol (MCP) servers, built with Python, Pydantic, and Neo4j.


## Features

- **Multi-Registry Scraping**: Automatically discovers MCP servers from:
  - GitHub repositories
  - mcp.so
  - Glama.ai (including glama.json files)
  - Mastra.ai MCP registry
- **Intelligent Categorization**: Automatically categorizes servers by functionality, data types, and operations
- **Relationship Inference**: Discovers relationships between servers based on similarity, complementarity, and dependencies
- **Versioned Storage**: Maintains historical snapshots with change detection
- **Neo4j Integration**: Loads data into Neo4j graph database for advanced querying
- **Resumable Operations**: Efficiently handles incremental updates without re-downloading unchanged data
- **Enhanced Service Management**: Robust start/stop scripts with status monitoring and process validation

## Architecture

### Core Components

- **`src/models.py`**: Pydantic models for servers, relationships, and ontology
- **`src/scrapers.py`**: Multi-registry scraping system with resumable operations
- **`src/neo4j_integration.py`**: Neo4j database integration and relationship inference
- **`src/main.py`**: Main orchestration script
- **`.config.yaml`**: Configuration for databases, APIs, and scraping parameters
- **`start.sh`**: Enhanced service startup with validation and conflict detection
- **`stop.sh`**: Comprehensive service management with status monitoring and restart capabilities

### Data Model

The system models MCP servers with rich metadata including:
- Basic information (name, description, author, version)
- Technical details (language, installation, capabilities)
- Categorization (functionality, operations, data types)
- Registry metadata (source, popularity, last updated)
- Tools, resources, and prompts exposed by the server

## Setup

### Prerequisites

1. **Neo4j Database**: Install and run Neo4j locally
   ```bash
   # Using Docker
   docker run -p 7474:7474 -p 7687:7687 -e NEO4J_AUTH=neo4j/mcpservers neo4j:latest
   ```

2. **GitHub Token**: Create a GitHub personal access token for API access
   - Go to GitHub Settings → Developer settings → Personal access tokens
   - Create a token with `repo` and `public_repo` permissions

### Installation

1. Clone the repository:
   ```bash
   git clone <repository-url>
   cd askg
   ```

2. Run the automated setup script:
   ```bash
   ./setup.sh
   ```
   
   This script will:
   - Check if `uv` is installed
   - Create necessary directories (`data/`, `data/registries/`, `data/snapshots/`, `logs/`)
   - Install dependencies using `uv pip install -r requirements.txt`
   - Create `.config.yaml` from `.config.example.yaml` if it doesn't exist
   - Provide next steps for configuration

3. Configure the system:
   - Edit `.config.yaml` to set your GitHub token
   - Adjust Neo4j connection details if needed
   - Modify scraping parameters as desired

## Testing

Run all tests using the automated test script:
```bash
./test.sh
```

This script will:
- Check if `uv` and `pytest` are available
- Automatically install `pytest` and `coverage` if needed
- Run all tests with verbose output and coverage reporting
- Provide helpful error messages and troubleshooting tips

For individual test runs:
```bash
uv run pytest tests/test_specific_file.py -v
```

## Usage

### Basic Usage

Build the complete knowledge graph:
```bash
python src/main.py
```

### Service Management

The project includes enhanced service management scripts for easy startup, monitoring, and shutdown of all components.

#### Starting All Services

Use the automated start script to run the complete AskG system:
```bash
./start.sh
```

This enhanced script will:
- **Check for conflicts**: Detect if services are already running
- **Validate ports**: Ensure ports 3200 and 8200 are available
- **Test Neo4j connection**: Verify database connectivity before starting
- **Start MCP server**: Launch the semantic search server on port 8200
- **Build and start frontend**: Compile and launch the chat interface on port 3200
- **Validate processes**: Confirm each service is running and listening on correct ports
- **Save process IDs**: Store PIDs for proper management

**Services Started:**
- **Frontend Chat Interface**: http://localhost:3200
- **MCP Server**: http://localhost:8200
- **Neo4j Database**: Local or remote (based on configuration)

#### Checking Service Status

Monitor the status of all services:
```bash
./stop.sh status
```

This provides detailed information about:
- Process status (running/stopped)
- Port availability
- Neo4j connection status
- PID information
- Service URLs

#### Stopping All Services

Gracefully stop all services:
```bash
./stop.sh stop
```

This enhanced script will:
- **Stop by PID**: Gracefully terminate processes using stored PIDs
- **Port cleanup**: Kill any remaining processes on ports 3200 and 8200
- **Remove PID file**: Clean up the `.askg.pid` file
- **Handle orphaned processes**: Clean up any processes that weren't properly tracked

#### Restarting Services

Restart all services in one command:
```bash
./stop.sh restart
```

This will:
- Stop all running services
- Wait 2 seconds for cleanup
- Start all services fresh
- Validate everything is running correctly

#### Service Management Commands

```bash
./start.sh                    # Start all services
./stop.sh status              # Check service status
./stop.sh restart             # Restart all services
./stop.sh stop                # Stop all services
./stop.sh help                # Show usage information
```

### Advanced Options

```bash
# Force refresh all registry data
python src/main.py --force-refresh

# Scrape specific registries only
python src/main.py --registries github glama

# Skip Neo4j loading (useful for development)
python src/main.py --skip-neo4j

# Clear Neo4j database before loading
python src/main.py --clear-neo4j

# Show statistics only
python src/main.py --stats-only
```

### Configuration

The `.config.yaml` file allows you to customize:

- **Neo4j connection**: URI, username, password
- **GitHub API**: Personal access token
- **Storage paths**: Local directories for data storage
- **Scraping parameters**: Timeouts, retry logic, user agents
- **Registry settings**: URLs and search parameters

## Data Storage

The system maintains organized local storage:

```
data/
├── registries/
│   ├── github/
│   │   ├── github_20240101_120000.json
│   │   └── github_20240102_120000.json
│   ├── glama/
│   ├── mcp_so/
│   └── mastra/
└── snapshots/
    └── combined_snapshots.json
```

Each registry snapshot is timestamped and includes:
- Server metadata
- Scraping timestamp
- Data checksums for change detection
- Source URLs and metadata

## Neo4j Queries

Once loaded, you can query the knowledge graph using Cypher:

### Find Popular Servers
```cypher
MATCH (s:Server) 
WHERE s.popularity_score IS NOT NULL
RETURN s.name, s.description, s.popularity_score
ORDER BY s.popularity_score DESC 
LIMIT 10
```

### Find Servers by Category
```cypher
MATCH (s:Server)
WHERE 'database' IN s.categories
RETURN s.name, s.description, s.repository
```

### Discover Server Relationships
```cypher
MATCH (s1:Server)-[r:RELATES_TO]->(s2:Server)
WHERE r.confidence_score > 0.7
RETURN s1.name, r.type, s2.name, r.confidence_score
ORDER BY r.confidence_score DESC
```

### Find Similar Servers
```cypher
MATCH (s:Server {name: 'your-server-name'})
MATCH (s)-[r:RELATES_TO {type: 'similar_functionality'}]->(similar:Server)
RETURN similar.name, similar.description, r.confidence_score
ORDER BY r.confidence_score DESC
```

### Category Statistics
```cypher
MATCH (s:Server)
UNWIND s.categories as category
RETURN category, COUNT(s) as server_count
ORDER BY server_count DESC
```

## Extending the System

### Adding New Registries

1. Create a new scraper class inheriting from `BaseScraper`
2. Add the registry to the `RegistrySource` enum
3. Implement the `scrape()` method
4. Register the scraper in `ScrapingOrchestrator`

### Custom Relationship Types

1. Add new relationship types to the `RelationshipType` enum
2. Implement inference logic in `RelationshipInferencer`
3. Update Neo4j queries as needed

### Enhanced Categorization

1. Modify the `categorize_server()` method in `BaseScraper`
2. Add new categories to the `ServerCategory` enum
3. Update the ontology creation in `main.py`

## Troubleshooting

### Common Issues

1. **GitHub Rate Limiting**: Ensure you have a valid GitHub token configured
2. **Neo4j Connection**: Verify Neo4j is running and credentials are correct
3. **Missing Dependencies**: Install all required packages from `requirements.txt` (recommended: use `uv pip install -r requirements.txt`)
4. **Memory Issues**: For large datasets, consider increasing system memory or implementing pagination
5. **Port Conflicts**: If services fail to start, check if ports 3200 or 8200 are already in use with `./stop.sh status`

### Service Management Issues

1. **Services won't start**: Run `./stop.sh status` to check for conflicts
2. **Port already in use**: Use `./stop.sh stop` to clean up existing processes
3. **Stale PID files**: The scripts automatically detect and handle stale PID files
4. **Process validation failures**: Check logs for specific error messages

### Debug Mode

Enable detailed logging by setting environment variables:
```bash
export PYTHONPATH=.
export DEBUG=1
python src/main.py
```

## Contributing

1. Fork the repository
2. Create a feature branch
3. Add tests for new functionality (place test files in the `tests/` directory)
4. Run tests to ensure everything works: `./test.sh`
5. Submit a pull request

## License

This project is licensed under the MIT License - see the LICENSE file for details.
